{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:06:24.124032Z",
     "start_time": "2024-05-30T06:06:22.815712Z"
    },
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.interpolate import interp1d"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2485881d0acae6b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:17:48.875095Z",
     "start_time": "2024-05-30T06:17:48.862086Z"
    }
   },
   "source": [
    "\n",
    "def slide_func(data, window_size, iter):\n",
    "    if iter >= window_size:\n",
    "        if iter % (1 * 512) == 0:\n",
    "            sliding_window_start = iter - window_size\n",
    "            sliding_window_end = iter\n",
    "            sliding_window = np.array(data[sliding_window_start:sliding_window_end])  # sliding_window ~ y\n",
    "            return sliding_window\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def filter_data(data):\n",
    "    # Bandpass filter\n",
    "    band = [0.5 / (0.5 * 512), 40 / (0.5 * 512)]\n",
    "    b, a = sp.signal.butter(4, band, btype='band', analog=False, output='ba')\n",
    "    data = sp.signal.lfilter(b, a, data)\n",
    "\n",
    "    # Filter for EMG by interpolated\n",
    "    filtered_data = data[(np.abs(data) <= 256)]\n",
    "    x = np.arange(len(filtered_data))\n",
    "    interpolated_data = interp1d(x, filtered_data)(np.linspace(0, len(filtered_data) - 1, len(data)))\n",
    "    return interpolated_data\n",
    "\n",
    "def hjorth_parameters(signal):\n",
    "    diff1 = np.diff(signal) # Tính đạo hàm bậc nhất\n",
    "    diff2 = np.diff(diff1)  # Tính đạo hàm bậc hai\n",
    "\n",
    "    activity = np.var(signal)      # Activity (A)\n",
    "    mobility = np.sqrt(np.var(diff1) / activity)  # Mobility (B)\n",
    "    complexity = np.sqrt(np.var(diff2) / np.var(diff1)) / mobility  # Complexity (C)\n",
    "\n",
    "    return activity, mobility, complexity\n",
    "\n",
    "def FeatureExtract(data, number):\n",
    "    f, t, Zxx = sp.signal.stft(data, 512, nperseg=15 * 512, noverlap=14 * 512)\n",
    "    delta = np.array([], dtype=float)\n",
    "    theta = np.array([], dtype=float)\n",
    "    alpha = np.array([], dtype=float)\n",
    "    beta = np.array([], dtype=float)\n",
    "\n",
    "    for i in range(0, int(t[-1])):\n",
    "        indices = np.where((f >= 0.5) & (f <= 4))[0]\n",
    "        delta = np.append(delta, np.sum(np.abs(Zxx[indices, i])))\n",
    "\n",
    "        indices = np.where((f >= 4) & (f <= 8))[0]\n",
    "        theta = np.append(theta, np.sum(np.abs(Zxx[indices, i])))\n",
    "\n",
    "        indices = np.where((f >= 8) & (f <= 13))[0]\n",
    "        alpha = np.append(alpha, np.sum(np.abs(Zxx[indices, i])))\n",
    "\n",
    "        indices = np.where((f >= 13) & (f <= 30))[0]\n",
    "        beta = np.append(beta, np.sum(np.abs(Zxx[indices, i])))\n",
    "\n",
    "    abr = alpha / beta\n",
    "    tbr = theta / beta\n",
    "    dbr = delta / beta\n",
    "    tar = theta / alpha\n",
    "    dar = delta / alpha\n",
    "    dtabr = (alpha + beta) / (delta + theta)\n",
    "\n",
    "    diction = {\n",
    "        \"delta\": delta,\n",
    "        \"theta\": theta,\n",
    "        \"alpha\": alpha,\n",
    "        \"beta\": beta,\n",
    "        \"abr\": abr,\n",
    "        \"tbr\": tbr,\n",
    "        \"dbr\": dbr,\n",
    "        \"tar\": tar,\n",
    "        \"dar\": dar,\n",
    "        \"dtabr\": dtabr,\n",
    "        \"label\": number\n",
    "    }\n",
    "\n",
    "    return diction\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3aabee5f7606e075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:14:55.504555Z",
     "start_time": "2024-05-30T06:14:55.345906Z"
    }
   },
   "source": [
    "import os\n",
    "folder_path = '../Data'\n",
    "\n",
    "task1_data = []\n",
    "task2_data = []\n",
    "task3_data = []\n",
    "task4_data = []\n",
    "task5_data = []\n",
    "\n",
    "print(os.listdir(folder_path))\n",
    "\n",
    "for dir in os.listdir(folder_path)[1:]:\n",
    "    subject_path = os.path.join(folder_path, dir)\n",
    "\n",
    "    for filename in os.listdir(subject_path):\n",
    "        # Kiểm tra nếu là file .txt\n",
    "        if filename.endswith(\".txt\"):\n",
    "            # Đọc dữ liệu từ file\n",
    "            file_data = np.loadtxt(os.path.join(subject_path, filename))\n",
    "\n",
    "        match filename[:-4]:\n",
    "            case \"task1\": \n",
    "                task1_data.append(file_data)\n",
    "            case \"task2\":\n",
    "                task2_data.append(file_data)\n",
    "            case \"task3\":\n",
    "                task3_data.append(file_data)\n",
    "            case \"task4\":\n",
    "                task4_data.append(file_data)\n",
    "            case \"task5\":\n",
    "                task5_data.append(file_data)\n",
    "            case _:\n",
    "                print(\"file name is not correct!\")\n",
    "            # print(filename)\n",
    "        \n",
    "\n",
    "# task1_data = np.concatenate(task1_data, axis = 0)\n",
    "task2_data = np.concatenate(task2_data, axis = 0)\n",
    "task3_data = np.concatenate(task3_data, axis = 0)\n",
    "task4_data = np.concatenate(task4_data, axis = 0)\n",
    "task5_data = np.concatenate(task5_data, axis = 0)\n",
    "\n",
    "# print(task1_data.shape)\n",
    "print(task2_data.shape)\n",
    "print(task3_data.shape)\n",
    "print(task4_data.shape)\n",
    "print(task5_data.shape)\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4fa963ea54b21e8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:17:54.781757Z",
     "start_time": "2024-05-30T06:17:54.378369Z"
    }
   },
   "source": [
    "# Task1 = filter_data(task1_data)\n",
    "Task2 = filter_data(task2_data)\n",
    "Task3 = filter_data(task4_data)\n",
    "Task4 = filter_data(task3_data)\n",
    "Task5 = filter_data(task5_data)\n",
    "\n",
    "\n",
    "# Extract features\n",
    "# task1_features = FeatureExtract(Task1, 0)\n",
    "task2_features = FeatureExtract(Task2, 0)\n",
    "task3_features = FeatureExtract(Task3, 1)\n",
    "task4_features = FeatureExtract(Task4, 2)\n",
    "task5_features = FeatureExtract(Task5, 3)\n",
    "\n",
    "\n",
    "# Save features to CSV\n",
    "# save_to_csv(task1_features, '../Data/CSV/Task1.csv')\n",
    "save_to_csv(task2_features, '../CSV/Task2.csv')\n",
    "save_to_csv(task3_features, '../CSV/Task3.csv')\n",
    "save_to_csv(task4_features, '../CSV/Task4.csv')\n",
    "save_to_csv(task5_features, '../CSV/Task5.csv')\n",
    "\n",
    "print(\"EEG features saved to csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e209017f5f7009a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:19:22.932218Z",
     "start_time": "2024-05-30T06:19:22.907193Z"
    }
   },
   "source": [
    "# Task1 = pd.read_csv('../CSV/Task1.csv')\n",
    "Task2 = pd.read_csv('../CSV/Task2.csv')\n",
    "Task3 = pd.read_csv('../CSV/Task3.csv')\n",
    "Task4 = pd.read_csv('../CSV/Task4.csv')\n",
    "Task5 = pd.read_csv('../CSV/Task5.csv')\n",
    "\n",
    "\n",
    "# print(Task1.shape)\n",
    "print(Task2.shape)\n",
    "print(Task3.shape)\n",
    "print(Task4.shape)\n",
    "print(Task5.shape)\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d2c13ed2e827231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:20:34.832114Z",
     "start_time": "2024-05-30T06:20:34.028442Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Giả sử Task1, Task2, Task3, Task4, Task5 là các DataFrame hoặc Series có cột 'delta'\n",
    "\n",
    "# plt.plot(Task1['delta'], label='Task1')\n",
    "plt.plot(Task2['delta'], label='Task2')\n",
    "plt.plot(Task3['delta'], label='Task3')\n",
    "plt.plot(Task4['delta'], label='Task4')\n",
    "plt.plot(Task5['delta'], label='Task5')\n",
    "\n",
    "# Thêm chú thích vào biểu đồ\n",
    "plt.legend()\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0da95dd88ae97fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:21:10.082688Z",
     "start_time": "2024-05-30T06:21:09.995101Z"
    }
   },
   "source": [
    "# plt.plot(Task1['alpha'], label='Task1')\n",
    "plt.plot(Task2['alpha'], label='Task2')\n",
    "plt.plot(Task3['alpha'], label='Task3')\n",
    "plt.plot(Task4['alpha'], label='Task4')\n",
    "plt.plot(Task5['alpha'], label='Task5')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "229dd12c5085a869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:21:24.104546Z",
     "start_time": "2024-05-30T06:21:24.016961Z"
    }
   },
   "source": [
    "# plt.plot(Task1['beta'], label='Task1')\n",
    "plt.plot(Task2['beta'], label='Task2')\n",
    "plt.plot(Task3['beta'], label='Task3')\n",
    "plt.plot(Task4['beta'], label='Task4')\n",
    "plt.plot(Task5['beta'], label='Task5')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b055ff2c0fefc26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:21:40.495864Z",
     "start_time": "2024-05-30T06:21:40.403269Z"
    }
   },
   "source": [
    "# plt.plot(Task1['theta'], label='Task1')\n",
    "plt.plot(Task2['theta'], label='Task2')\n",
    "plt.plot(Task3['theta'], label='Task3')\n",
    "plt.plot(Task4['theta'], label='Task4')\n",
    "plt.plot(Task5['theta'], label='Task5')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aa05286624b8f40e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:50:18.129225Z",
     "start_time": "2024-05-30T06:50:18.059160Z"
    }
   },
   "source": [
    "def df_to_X_y(df, window_size=15):\n",
    "  df_as_np = df.to_numpy()\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size):\n",
    "    row = [[a[:-1]] for a in df_as_np[i:i+window_size]]\n",
    "    X.append(row)\n",
    "    label = df_as_np[i+window_size][-1]\n",
    "    y.append(label)\n",
    "  return np.array(X), np.array(y)\n",
    "\n",
    "# feature_task1, label_task2 = df_to_X_y(Task1)\n",
    "feature_task2, label_task2 = df_to_X_y(Task2)\n",
    "feature_task3, label_task3 = df_to_X_y(Task3)\n",
    "feature_task4, label_task4 = df_to_X_y(Task4)\n",
    "feature_task5, label_task5 = df_to_X_y(Task5)\n",
    "\n",
    "\n",
    "# feature_task1 = np.squeeze(feature_task1)\n",
    "feature_task2 = np.squeeze(feature_task2)\n",
    "feature_task3 = np.squeeze(feature_task3)\n",
    "feature_task4 = np.squeeze(feature_task4)\n",
    "feature_task5 = np.squeeze(feature_task5)\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4406a9e3b6158b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:50:21.077406Z",
     "start_time": "2024-05-30T06:50:21.061391Z"
    }
   },
   "source": [
    "print(feature_task2[1])\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8246567c9ebfdb3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:50:22.615227Z",
     "start_time": "2024-05-30T06:50:22.604217Z"
    }
   },
   "source": [
    "features = np.vstack((feature_task2, feature_task3, feature_task4, feature_task5))\n",
    "labels = np.concatenate((label_task2, label_task3, label_task4, label_task5))\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "32506ea02604e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:50:24.386552Z",
     "start_time": "2024-05-30T06:50:24.362531Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, MultiHeadAttention, Input, DepthwiseConv2D, LSTM, Bidirectional,Embedding, Input,GlobalAveragePooling2D,GlobalAveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, GRU\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "\n",
    "batch_size = 32\n",
    "data_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "data_test = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "data_train = data_train.repeat(10).batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE).shuffle(buffer_size=500)\n",
    "data_test = data_test.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print(X_train[1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "afb0e1b085e9f885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:50:34.104682Z",
     "start_time": "2024-05-30T06:50:34.061642Z"
    }
   },
   "source": [
    "weight_decay = 0.001\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(15, 10), kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "print(model.summary())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c277a031b5494d72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:50:52.170735Z",
     "start_time": "2024-05-30T06:50:48.091796Z"
    }
   },
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "model.fit(data_train, validation_data=data_test, epochs=10)\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c7bad13cc9932e56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:50:54.978862Z",
     "start_time": "2024-05-30T06:50:54.670767Z"
    }
   },
   "source": [
    "loss_train, acc_train = model.evaluate(data_train)\n",
    "loss_test, acc_test = model.evaluate(data_test)\n",
    "print(\"Train results: \", acc_train)\n",
    "print(\"Test results: \", acc_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4963eb622735caf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:51:36.554773Z",
     "start_time": "2024-05-30T06:51:36.447168Z"
    }
   },
   "source": [
    "train_predictions = model.predict(X_test)\n",
    "train_predictions_labels = np.argmax(train_predictions, axis=1)\n",
    "train_results = pd.DataFrame(data={'Train Predictions':train_predictions_labels, 'Actuals':y_test})\n",
    "train_results\n",
    "\n",
    "print(np.argmax(model.predict(features[1:3]), axis = 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "94b15276e1fa7238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T06:51:40.509725Z",
     "start_time": "2024-05-30T06:51:40.393111Z"
    }
   },
   "source": [
    "# Make predictions on the test set\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, train_predictions_labels, labels=[0, 1,2,3]))\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, train_predictions_labels), display_labels=[\"Task2\", \"Task3\", \"Task4\", \"Task5\"])\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cbcf132646d95c1a",
   "metadata": {},
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(\"../trained_model/ANN.h5\", \"wb\"))\n",
    "\n",
    "# pickle.dump(model, open(\"/Users/nguyentrithanh/Downloads/OneDrive_1_29-5-2024/ZZZZZ/trained_model/ANN.h5\", \"wb\"))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb925ab",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
